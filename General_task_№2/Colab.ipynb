{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7c19b03-498e-4dbb-9c2d-244151e08649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+--------------------+------------+--------------------+--------------------+\n",
      "| id|                name|               email|                city|         age|              salary|   registration_date|\n",
      "+---+--------------------+--------------------+--------------------+------------+--------------------+--------------------+\n",
      "|  1|             ATAGAEV|78nbc2dff41nak647...|vbn345967nd34sf33...|   six6five5|four4three1eight8...|one1nine9eight8se...|\n",
      "|  2|78nbc2dff41nak647...|78nbc2dff41nak647...|vbn345967nd34sf33...| eight8nine9|eight8one1two1fiv...|two1zero1zero1fiv...|\n",
      "|  3|78nbc2dff41nak647...|78nbc2dff41nak647...|vbn345967nd34sf33...|  two1seven7|one1four4zero1nin...|two1zero1one1seve...|\n",
      "|  4|78nbc2dff41nak647...|78nbc2dff41nak647...|vbn345967nd34sf33...|   five5six6|nine9five5eight8e...|one1nine9eight8ei...|\n",
      "|  5|78nbc2dff41nak647...|78nbc2dff41nak647...|vbn345967nd34sf33...| eight8five5|two1zero1five5zer...|one1nine9seven7th...|\n",
      "|  6|78nbc2dff41nak647...|78nbc2dff41nak647...|vbn345967nd34sf33...|   two1five5|three1five5four4n...|two1zero1one1nine...|\n",
      "|  7|78nbc2dff41nak647...|78nbc2dff41nak647...|vbn345967nd34sf33...|  six6seven7|one1one1two1seven...|one1nine9nine9zer...|\n",
      "|  8|78nbc2dff41nak647...|78nbc2dff41nak647...|vbn345967nd34sf33...| four4seven7|one1three1eight8t...|two1zero1zero1fou...|\n",
      "|  9|78nbc2dff41nak647...|78nbc2dff41nak647...|                NULL|   two1five5|one1four4nine9sev...|two1zero1two1four...|\n",
      "| 10|78nbc2dff41nak647...|78nbc2dff41nak647...|                NULL|  nine9four4|five5six6zero1thr...|two1zero1one1nine...|\n",
      "| 11|78nbc2dff41nak647...|78nbc2dff41nak647...|vbn345967nd34sf33...|  three1six6|eight8six6four4ze...|two1zero1one1nine...|\n",
      "| 12|78nbc2dff41nak647...|78nbc2dff41nak647...|vbn345967nd34sf33...|  four4zero1|one1six6seven7eig...|two1zero1one1eigh...|\n",
      "| 13|78nbc2dff41nak647...|78nbc2dff41nak647...|vbn345967nd34sf33...|eight8three1|five5one1nine9sev...|one1nine9nine9sev...|\n",
      "| 14|78nbc2dff41nak647...|78nbc2dff41nak647...|vbn345967nd34sf33...|seven7eight8|one1two1zero1four...|two1zero1zero1two...|\n",
      "| 15|78nbc2dff41nak647...|78nbc2dff41nak647...|vbn345967nd34sf33...| five5eight8|six6five5five5one...|two1zero1zero1two...|\n",
      "| 16|78nbc2dff41nak647...|78nbc2dff41nak647...|vbn345967nd34sf33...|  seven7two1|                NULL|one1nine9eight8fo...|\n",
      "| 17|78nbc2dff41nak647...|78nbc2dff41nak647...|vbn345967nd34sf33...|seven7eight8|three1three1two1f...|one1nine9eight8ze...|\n",
      "| 18|78nbc2dff41nak647...|78nbc2dff41nak647...|vbn345967nd34sf33...|        NULL|three1six6five5ni...|two1zero1one1one1...|\n",
      "| 19|78nbc2dff41nak647...|78nbc2dff41nak647...|vbn345967nd34sf33...|   nine9two1|one1three1five5on...|one1nine9six6five...|\n",
      "| 20|78nbc2dff41nak647...|78nbc2dff41nak647...|vbn345967nd34sf33...|    two1two1|four4six6zero1eig...|two1zero1two1one1...|\n",
      "+---+--------------------+--------------------+--------------------+------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, concat, lit, when, rand, current_date, date_add, date_format, udf\n",
    "from pyspark.sql.types import StringType\n",
    "import os\n",
    "\n",
    "spark = SparkSession.builder.appName(\"SyntheticData\") \\\n",
    "    .config(\"spark.master\", \"local\") \\\n",
    "    .config('spark.driver.memory', '4g') \\\n",
    "    .config('spark.executor.cores', '4') \\\n",
    "    .config('spark.executor.memory', '8g') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "\n",
    "# Указываем сколько строк надо сгенерировать\n",
    "numbers_row = 100\n",
    "\n",
    "# Генерация данных для колонок id, name, city, email, age, salary, registration_date\n",
    "data = [(i, f\"Names_{i}\", f\"Cityname_{i}\") for i in range(1, numbers_row + 1)]\n",
    "df = spark.createDataFrame(data, [\"id\", \"name\", \"city\"])\n",
    "\n",
    "df = df.withColumn(\"email\", concat(col(\"name\"), lit(\"@example.\"), when(col(\"id\") % 2 == 0, \"ru\").otherwise(\"com\"))) \\\n",
    "    .withColumn(\"age\", (rand() * 78 + 18).cast(\"int\")) \\\n",
    "    .withColumn(\"salary\", (rand() * 150000 + 19242).cast(\"int\")) \\\n",
    "    .withColumn(\"registration_date\", date_add(current_date(), - (rand() * (col(\"age\") - 18)).cast(\"int\") * 365))\n",
    "\n",
    "df.cache()  # Кеширование DataFrame для более быстрой обработки\n",
    "\n",
    "# Замена 5% данных на значение NULL\n",
    "columns = [\"name\", \"email\", \"city\", \"age\", \"salary\", \"registration_date\"]\n",
    "df = df.select(\"id\", *[when(rand() <= 0.05, None).otherwise(col(column)).alias(column) for column in columns])\n",
    "\n",
    "encryption_dict = {\n",
    "    \"A\": \"1212abb\", \"B\": \"ad\", \"C\": \"vbn345\", \"D\": \"xyz678\",\n",
    "    \"E\": \"123eqr\", \"F\": \"890fgh\", \"G\": \"poi0ty\", \"H\": \"qwabc1\",\n",
    "    \"I\": \"dfghe2\", \"J\": \"456aks\", \"K\": \"zxcvw3\", \"L\": \"mnb22\",\n",
    "    \"M\": \"efg56\", \"N\": \"78nbc\", \"O\": \"hijk4\", \"P\": \"or890\",\n",
    "    \"Q\": \"nbvc5\", \"R\": \"ytser6\", \"S\": \"vc123\", \"T\": \"gh78\",\n",
    "    \"U\": \"pqws7\", \"V\": \"zxc14\", \"W\": \"tyui9\", \"X\": \"asqw35\",\n",
    "    \"Y\": \"dert2\", \"Z\": \"qwert8\",\n",
    "    \n",
    "    \"a\": \"2dff4\", \"b\": \"fa25gf\", \"c\": \"1rs351\", \"d\": \"14fs3f\",\n",
    "    \"e\": \"7jgvw34\", \"f\": \"7gs3gd3\", \"g\": \"2fas3542\", \"h\": \"45dw24\",\n",
    "    \"i\": \"967nd\", \"j\": \"3fa37h\", \"k\": \"asf1fw1\", \"l\": \"65ser2\",\n",
    "    \"m\": \"1nak64\", \"n\": \"6jsl7\", \"o\": \"5gd35\", \"p\": \"34ts2f\",\n",
    "    \"q\": \"47jdz\", \"r\": \"1d5gnn7\", \"s\": \"2vsf52\", \"t\": \"34sf33\",\n",
    "    \"u\": \"126asv45\", \"v\": \"zex33ggg7\", \"w\": \"4ssffs4\", \"x\": \"fs5juo\",\n",
    "    \"y\": \"der91ghy\", \"z\": \"552gvc\",\n",
    "\n",
    "    \"0\": \"zero1\", \"1\": \"one1\", \"2\": \"two1\", \"3\": \"three1\",\n",
    "    \"4\": \"four4\", \"5\": \"five5\", \"6\": \"six6\", \"7\": \"seven7\",\n",
    "    \"8\": \"eight8\", \"9\": \"nine9\",\n",
    "    \n",
    "    \" \": \"space0\", \"!\": \"lk765i\", \"\\\"\": \"quote2\", \"#\": \"hash3\",\n",
    "    \"$\": \"dollar4\", \"%\": \"percent5\", \"&\": \"and6\", \"'\": \"quote1\",\n",
    "    \"(\": \"leftpar7\", \")\": \"rightpar8\", \"*\": \"star9\", \"+\": \"plus10\",\n",
    "    \",\": \"comma11\", \"-\": \"dash12\", \".\": \"dot13\", \"/\": \"slash14\",\n",
    "    \":\": \"colon15\", \";\": \"semicolon16\", \"<\": \"lessthan17\",\n",
    "    \"=\": \"equal18\", \">\": \"greaterthan19\", \"?\": \"port489\",\n",
    "    \"@\": \"atmark20\", \"[\": \"leftbracket21\", \"\\\\\": \"backslash22\",\n",
    "    \"]\": \"rightbracket23\", \"^\": \"caret24\", \"_\": \"underscore25\",\n",
    "    \"`\": \"backtick26\", \"{\": \"leftcurly27\", \"|\": \"pipe28\",\n",
    "    \"}\": \"rightcurly29\", \"~\": \"tilde30\"\n",
    "}\n",
    "\n",
    "# Отправляем на узлы кластера\n",
    "broadcast_dict = sc.broadcast(encryption_dict).value\n",
    "\n",
    "# Функция для шифрования\n",
    "def encrypt_string(input_string):\n",
    "    if input_string is None:\n",
    "        return None\n",
    "    return ''.join(broadcast_dict.get(char, char) for char in str(input_string))\n",
    "\n",
    "# Определяем UDF для запуска функции шифрования\n",
    "encrypt_udf = udf(encrypt_string, StringType())\n",
    "\n",
    "# Применяем UDF к колоннам\n",
    "df = df.withColumn(\"name\", encrypt_udf(col(\"name\"))) \\\n",
    "    .withColumn(\"email\", encrypt_udf(col(\"email\"))) \\\n",
    "    .withColumn(\"city\", encrypt_udf(col(\"city\"))) \\\n",
    "    .withColumn(\"age\", encrypt_udf(col(\"age\"))) \\\n",
    "    .withColumn(\"salary\", encrypt_udf(col(\"salary\"))) \\\n",
    "    .withColumn(\"registration_date\", encrypt_udf(col(\"registration_date\")))\n",
    "\n",
    "# Пишу свое имя на первой строке колонки name\n",
    "df = df.withColumn(\"name\", when(col(\"id\") == 1, \"ATAGAEV\").otherwise(col(\"name\")))\n",
    "\n",
    "# Установка текущей даты и количества строк для имени файла\n",
    "df_date = spark.sql(\"SELECT current_date()\")\n",
    "current_date = df_date.select(date_format(\"current_date\", \"yyyy-MM-dd\")).first()[0]\n",
    "name_csv = encrypt_string(numbers_row)\n",
    "\n",
    "# Путь к сохранению CSV файла\n",
    "path = f\"/home/jovyan/work/PySpark_test/config/temp/{current_date}-{name_csv}.csv\"\n",
    "path_rename = f\"/home/jovyan/work/PySpark_test/config/{current_date}-{name_csv}.csv\"\n",
    "# Запись DataFrame в CSV\n",
    "df.coalesce(1).write.csv(path, header=True, mode=\"overwrite\")  \n",
    "\n",
    "# Переименование сгенерированного файла\n",
    "for file in os.listdir(path):\n",
    "    file_path = os.path.join(path, file)\n",
    "    if file.startswith(\"part-\"):\n",
    "        os.rename(file_path, path_rename)\n",
    "\n",
    "# Удаление временных файлов и папки\n",
    "for file in os.listdir(path):\n",
    "    file_path = os.path.join(path, file)\n",
    "    os.remove(file_path)\n",
    "    \n",
    "os.rmdir(path)\n",
    "\n",
    "df.show()\n",
    "\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0055006-61f6-44f4-a04c-1f0860b22664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+--------------------+-----------+----+------+-----------------+\n",
      "| id|    name|               email|       city| age|salary|registration_date|\n",
      "+---+--------+--------------------+-----------+----+------+-----------------+\n",
      "|  1| ATAGAEV| Names_1@example.com| Cityname_1|  65| 43824|       1987-08-11|\n",
      "|  2| Names_2|  Names_2@example.ru| Cityname_2|  89| 81252|       2005-08-06|\n",
      "|  3| Names_3| Names_3@example.com| Cityname_3|  27|140990|       2017-08-03|\n",
      "|  4| Names_4|  Names_4@example.ru| Cityname_4|  56| 95884|       1988-08-10|\n",
      "|  5| Names_5| Names_5@example.com| Cityname_5|  85| 20506|       1973-08-14|\n",
      "|  6| Names_6|  Names_6@example.ru| Cityname_6|  25| 35493|       2019-08-03|\n",
      "|  7| Names_7| Names_7@example.com| Cityname_7|  67|112707|       1990-08-10|\n",
      "|  8| Names_8|  Names_8@example.ru| Cityname_8|  47|138321|       2004-08-06|\n",
      "|  9| Names_9| Names_9@example.com|       NULL|  25|149773|       2024-08-01|\n",
      "| 10|Names_10| Names_10@example.ru|       NULL|  94| 56038|       2019-08-03|\n",
      "| 11|Names_11|Names_11@example.com|Cityname_11|  36| 86408|       2019-08-03|\n",
      "| 12|Names_12| Names_12@example.ru|Cityname_12|  40|167814|       2018-08-03|\n",
      "| 13|Names_13|Names_13@example.com|Cityname_13|  83| 51973|       1997-08-08|\n",
      "| 14|Names_14| Names_14@example.ru|Cityname_14|  78|120447|       2002-08-07|\n",
      "| 15|Names_15|Names_15@example.com|Cityname_15|  58| 65513|       2002-08-07|\n",
      "| 16|Names_16| Names_16@example.ru|Cityname_16|  72|  NULL|       1984-08-11|\n",
      "| 17|Names_17|Names_17@example.com|Cityname_17|  78| 33244|       1980-08-12|\n",
      "| 18|Names_18| Names_18@example.ru|Cityname_18|NULL| 36599|       2011-08-05|\n",
      "| 19|Names_19|Names_19@example.com|Cityname_19|  92|135182|       1965-08-16|\n",
      "| 20|Names_20| Names_20@example.ru|Cityname_20|  22| 46080|       2021-08-02|\n",
      "+---+--------+--------------------+-----------+----+------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##########################################################################\n",
    "# Блок кода для дешифрования\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, udf, current_date, date_format\n",
    "from pyspark.sql.types import StringType\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "\n",
    "# Инициализация Spark\n",
    "spark = SparkSession.builder.appName(\"SyntheticData\") \\\n",
    "    .config(\"spark.master\", \"local\") \\\n",
    "    .config('spark.driver.memory', '4g') \\\n",
    "    .config('spark.executor.cores', '4') \\\n",
    "    .config('spark.executor.memory', '8g') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "\n",
    "# Указываем сколько было строк в зашифрованном файле\n",
    "numbers_row = 100\n",
    "\n",
    "encryption_dict = {\n",
    "    \"A\": \"1212abb\", \"B\": \"ad\", \"C\": \"vbn345\", \"D\": \"xyz678\",\n",
    "    \"E\": \"123eqr\", \"F\": \"890fgh\", \"G\": \"poi0ty\", \"H\": \"qwabc1\",\n",
    "    \"I\": \"dfghe2\", \"J\": \"456aks\", \"K\": \"zxcvw3\", \"L\": \"mnb22\",\n",
    "    \"M\": \"efg56\", \"N\": \"78nbc\", \"O\": \"hijk4\", \"P\": \"or890\",\n",
    "    \"Q\": \"nbvc5\", \"R\": \"ytser6\", \"S\": \"vc123\", \"T\": \"gh78\",\n",
    "    \"U\": \"pqws7\", \"V\": \"zxc14\", \"W\": \"tyui9\", \"X\": \"asqw35\",\n",
    "    \"Y\": \"dert2\", \"Z\": \"qwert8\",\n",
    "    \n",
    "    \"a\": \"2dff4\", \"b\": \"fa25gf\", \"c\": \"1rs351\", \"d\": \"14fs3f\",\n",
    "    \"e\": \"7jgvw34\", \"f\": \"7gs3gd3\", \"g\": \"2fas3542\", \"h\": \"45dw24\",\n",
    "    \"i\": \"967nd\", \"j\": \"3fa37h\", \"k\": \"asf1fw1\", \"l\": \"65ser2\",\n",
    "    \"m\": \"1nak64\", \"n\": \"6jsl7\", \"o\": \"5gd35\", \"p\": \"34ts2f\",\n",
    "    \"q\": \"47jdz\", \"r\": \"1d5gnn7\", \"s\": \"2vsf52\", \"t\": \"34sf33\",\n",
    "    \"u\": \"126asv45\", \"v\": \"zex33ggg7\", \"w\": \"4ssffs4\", \"x\": \"fs5juo\",\n",
    "    \"y\": \"der91ghy\", \"z\": \"552gvc\",\n",
    "\n",
    "    \"0\": \"zero1\", \"1\": \"one1\", \"2\": \"two1\", \"3\": \"three1\",\n",
    "    \"4\": \"four4\", \"5\": \"five5\", \"6\": \"six6\", \"7\": \"seven7\",\n",
    "    \"8\": \"eight8\", \"9\": \"nine9\",\n",
    "    \n",
    "    \" \": \"space0\", \"!\": \"lk765i\", \"\\\"\": \"quote2\", \"#\": \"hash3\",\n",
    "    \"$\": \"dollar4\", \"%\": \"percent5\", \"&\": \"and6\", \"'\": \"quote1\",\n",
    "    \"(\": \"leftpar7\", \")\": \"rightpar8\", \"*\": \"star9\", \"+\": \"plus10\",\n",
    "    \",\": \"comma11\", \"-\": \"dash12\", \".\": \"dot13\", \"/\": \"slash14\",\n",
    "    \":\": \"colon15\", \";\": \"semicolon16\", \"<\": \"lessthan17\",\n",
    "    \"=\": \"equal18\", \">\": \"greaterthan19\", \"?\": \"port489\",\n",
    "    \"@\": \"atmark20\", \"[\": \"leftbracket21\", \"\\\\\": \"backslash22\",\n",
    "    \"]\": \"rightbracket23\", \"^\": \"caret24\", \"_\": \"underscore25\",\n",
    "    \"`\": \"backtick26\", \"{\": \"leftcurly27\", \"|\": \"pipe28\",\n",
    "    \"}\": \"rightcurly29\", \"~\": \"tilde30\"\n",
    "}\n",
    "    \n",
    "# Отправляем на узлы кластера\n",
    "broadcast_dict = sc.broadcast(encryption_dict).value\n",
    "\n",
    "# Функция для шифрования\n",
    "def encrypt_string(input_string):\n",
    "    if input_string is None:\n",
    "        return None\n",
    "    return ''.join(broadcast_dict.get(char, char) for char in str(input_string))\n",
    "\n",
    "# Установка текущей даты и количества строк для имени файла\n",
    "df_date = spark.sql(\"SELECT current_date()\")\n",
    "current_date = df_date.select(date_format(\"current_date\", \"yyyy-MM-dd\")).first()[0]\n",
    "name_csv = encrypt_string(numbers_row)\n",
    "path_open = f\"/home/jovyan/work/PySpark_test/config/{current_date}-{name_csv}.csv\"\n",
    "\n",
    "# Чтение DataFrame из CSV\n",
    "df = spark.read.csv(path_open, header=True)\n",
    "\n",
    "# Создание обратного словаря\n",
    "decryption_dict = {v: k for k, v in broadcast_dict.items()}\n",
    "\n",
    "# Функция для дешифрования\n",
    "def decrypt_string(encrypted):\n",
    "    if encrypted is None:\n",
    "        return None \n",
    "    decrypted = []\n",
    "    pattern = '|'.join(re.escape(key) for key in decryption_dict.keys())\n",
    "    matches = re.findall(pattern, encrypted)\n",
    "    if not matches:\n",
    "        return encrypted\n",
    "    for match in matches:\n",
    "        decrypted.append(decryption_dict.get(match, match))\n",
    "    return ''.join(decrypted)\n",
    "\n",
    "# Определяем UDF для дешифрования\n",
    "decrypt_udf = udf(decrypt_string, StringType())\n",
    "\n",
    "# Применяем UDF к нужным колоннам\n",
    "df = df.withColumn(\"name\", decrypt_udf(col(\"name\"))) \\\n",
    "    .withColumn(\"email\", decrypt_udf(col(\"email\"))) \\\n",
    "    .withColumn(\"city\", decrypt_udf(col(\"city\"))) \\\n",
    "    .withColumn(\"age\", decrypt_udf(col(\"age\"))) \\\n",
    "    .withColumn(\"salary\", decrypt_udf(col(\"salary\"))) \\\n",
    "    .withColumn(\"registration_date\", decrypt_udf(col(\"registration_date\")))\n",
    "\n",
    "# Путь к сохранению CSV файла\n",
    "path = f\"/home/jovyan/work/PySpark_test/config/temp/{current_date}-dev.csv\"\n",
    "path_rename = f\"/home/jovyan/work/PySpark_test/config/{current_date}-dev.csv\"\n",
    "# Запись DataFrame в CSV\n",
    "df.coalesce(1).write.csv(path, header=True, mode=\"overwrite\")  \n",
    "\n",
    "# Переименование сгенерированного файла\n",
    "for file in os.listdir(path):\n",
    "    file_path = os.path.join(path, file)\n",
    "    if file.startswith(\"part-\"):\n",
    "        os.rename(file_path, path_rename)\n",
    "\n",
    "# Удаление временных файлов и папки\n",
    "for file in os.listdir(path):\n",
    "    file_path = os.path.join(path, file)\n",
    "    os.remove(file_path)\n",
    "    \n",
    "os.rmdir(path)\n",
    "\n",
    "df.show()\n",
    "\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e1e4c7-15d3-4232-bbfc-a3ad900cf5a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
